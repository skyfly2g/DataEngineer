{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823164ae",
   "metadata": {},
   "source": [
    "## S3 連接操作\n",
    "\n",
    "**S3 連接參數**\n",
    "\n",
    "為了教學的目的, 學院在地端啟動了Minio的服務來模擬公有雲的s3服務。\n",
    "\n",
    "請使用以下的帳號來登入Minio:\n",
    "\n",
    "* `endpoint_url` (s3服務的網路位址): **http://10.34.124.114:9500**\n",
    "* `aws_access_key_id` (使用者帳號): **demo**\n",
    "* `aws_secret_access_key` (使用者密碼): **demo8888**\n",
    "* `region_name` (區域編碼): **us-east-1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092af00",
   "metadata": {},
   "source": [
    "**範例數據**: `nyc_taxi_dataset.zip`檔案是`紐約市計程車和禮車協會`所發佈的一個公開資料集。\n",
    "\n",
    "* 檔案目錄: `data/nyc_taxi_dataset.zip`\n",
    "* 資料筆數: 729,322 （73萬筆）\n",
    "* 資料格式: CSV\n",
    "\n",
    "資料欄位:\n",
    "* id - 車程編號\n",
    "* vendor_id - 計程車行編號\n",
    "* pickup_datetime - 上車日期時間\n",
    "* dropoff_datetime - 下車日期時間\n",
    "* passenger_count - 乘客人數\n",
    "* pickup_longitude - 上車經度\n",
    "* pickup_latitude - 上車緯度\n",
    "* dropoff_longitude - 下車經度\n",
    "* dropoff_latitude - 下車緯度\n",
    "* store_and_fwd_flag - 是否直接連線上傳b Y/N\n",
    "* trip_duration - 車程持續時間(以秒為單位)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c0b4d",
   "metadata": {},
   "source": [
    "## 作業#01\n",
    "\n",
    "1.在MiniO Web建立你的bucket(`de+{工號}`)。  \n",
    "2.將CSV文件加載到DataFrame中並導出成Parquet文件(`to_parquet`, 並且以gzip來進行壓縮), 然後上傳到學員個人的bucket。\n",
    "\n",
    "* **bucket_name**: de+{工號}\n",
    "* **object_key**: nyc_taxi_trip_duration.parquet.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d89b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
      "0  id1080784          2  2016-02-29 16:40:21  2016-02-29 16:47:01   \n",
      "1  id0889885          1  2016-03-11 23:35:37  2016-03-11 23:53:57   \n",
      "2  id0857912          2  2016-02-21 17:59:33  2016-02-21 18:26:48   \n",
      "3  id3744273          2  2016-01-05 09:44:31  2016-01-05 10:03:32   \n",
      "4  id0232939          1  2016-02-17 06:42:23  2016-02-17 06:56:31   \n",
      "5  id1918069          2  2016-02-14 18:31:42  2016-02-14 18:55:57   \n",
      "6  id2429028          1  2016-04-20 20:30:14  2016-04-20 20:36:51   \n",
      "7  id1663798          2  2016-06-19 16:48:14  2016-06-19 17:06:35   \n",
      "8  id2436943          2  2016-03-28 19:17:03  2016-03-28 19:48:29   \n",
      "9  id2933909          1  2016-04-10 22:01:41  2016-04-10 22:25:30   \n",
      "\n",
      "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "0                1        -73.953918        40.778873         -73.963875   \n",
      "1                2        -73.988312        40.731743         -73.994751   \n",
      "2                2        -73.997314        40.721458         -73.948029   \n",
      "3                6        -73.961670        40.759720         -73.956779   \n",
      "4                1        -74.017120        40.708469         -73.988182   \n",
      "5                2        -73.993614        40.751884         -73.995422   \n",
      "6                1        -73.965080        40.758915         -73.976807   \n",
      "7                1        -73.963890        40.765434         -73.872429   \n",
      "8                2        -73.872887        40.774281         -73.979019   \n",
      "9                1        -73.987823        40.740982         -73.999153   \n",
      "\n",
      "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
      "0         40.771164                  N            400  \n",
      "1         40.694931                  N           1100  \n",
      "2         40.774918                  N           1635  \n",
      "3         40.780628                  N           1141  \n",
      "4         40.740631                  N            848  \n",
      "5         40.723862                  N           1455  \n",
      "6         40.764107                  N            397  \n",
      "7         40.774200                  N           1101  \n",
      "8         40.761879                  N           1886  \n",
      "9         40.686451                  N           1429  \n"
     ]
    }
   ],
   "source": [
    "## task01\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "MY_BUCKET_NAME = 'dez18033044'\n",
    "MY_OBJECT_KEY = 'nyc_taxi_trip_duration.parquet.gz'\n",
    "\n",
    "df_nyc_taxi_dataset = pd.read_csv(\"data/nyc_taxi_dataset.zip\", compression='zip')\n",
    "print(df_nyc_taxi_dataset.head(10))\n",
    "df_nyc_taxi_dataset.to_parquet(\"nyc_taxi_trip_duration.parquet.gz\", compression='gzip')\n",
    "# Upload csv to MinIO\n",
    "s3_resource = boto3.resource('s3',\n",
    "                    endpoint_url='http://10.34.124.114:9500',\n",
    "                    aws_access_key_id='demo',\n",
    "                    aws_secret_access_key='demo8888',\n",
    "                    region_name='us-east-1')\n",
    "\n",
    "s3_resource.Object(MY_BUCKET_NAME, MY_OBJECT_KEY).upload_file(Filename=\"nyc_taxi_trip_duration.parquet.gz\")\n",
    "print('Upload file to MinIO successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8d09b",
   "metadata": {},
   "source": [
    "## 作業#02\n",
    "\n",
    "透過教學的方法,來從s3 (minio)上讀取這個nyc_taxi_trip_duration.parquet.gz檔案, 並計算出總共有多少名乘客數(total passengers)。並打印出來。\n",
    "\n",
    "* **bucket_name**: de+{工號}\n",
    "* **object_key**: nyc_taxi_trip_duration.parquet.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5247501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download s3 object to local success!\n",
      "Total passengers: 1212173\n"
     ]
    }
   ],
   "source": [
    "## task02\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import tempfile\n",
    "\n",
    "total_passenger = 0\n",
    "MY_BUCKET_NAME = 'dez18033044'\n",
    "MY_OBJECT_KEY = 'nyc_taxi_trip_duration.parquet.gz'\n",
    "\n",
    "s3_resource = boto3.resource('s3',\n",
    "                    endpoint_url='http://10.34.124.114:9500',\n",
    "                    aws_access_key_id='demo',\n",
    "                    aws_secret_access_key='demo8888',\n",
    "                    region_name='us-east-1')\n",
    "\n",
    "with tempfile.NamedTemporaryFile('w+') as fp:\n",
    "    temp_filename = fp.name\n",
    "\n",
    "    # download s3 object to local folder\n",
    "    try:\n",
    "        s3_resource.Object(MY_BUCKET_NAME, MY_OBJECT_KEY).download_file(temp_filename)\n",
    "        print('Download s3 object to local success!')\n",
    "    except ClientError as e:\n",
    "        printt('Download s3 object to local fail:{e}')\n",
    "\n",
    "    # read CSV into DataFrame\n",
    "    df_nyc_taxi_dataset_01 = pd.read_parquet(temp_filename)\n",
    "    \n",
    "    total_passenger = df_nyc_taxi_dataset_01['passenger_count'].sum()\n",
    "\n",
    "print(f'Total passengers: {total_passenger}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0246daf",
   "metadata": {},
   "source": [
    "# 資料庫連接操作\n",
    "\n",
    "這個作業主要是要讓學員學習如何連接到關聯型資料庫並進行一些讀取與寫入的操作。同時為讓學員去思考, 將數據寫入到資料庫與寫入到BlobStorage服務的差別, 以及將數據從資料庫讀取與從BlobStorage服務來讀取在日常的數據ETL的設計上該如何去構思。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc063535",
   "metadata": {},
   "source": [
    "## 作業#03\n",
    "\n",
    "請使用DBAPI來連結到這個範例資料庫, 並請計算出15個資料表每一個資料表的Record Count的筆數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3096dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect [postgres] database successfully!\n",
      "{'category': (17,), 'film_category': (1000,), 'film': (1000,), 'language': (6,), 'film_actor': (5462,), 'inventory': (4581,), 'rental': (16044,), 'payment': (14606,), 'staff': (2,), 'actor': (200,), 'customer': (599,), 'address': (603,), 'city': (600,), 'country': (109,), 'store': (2,)}\n"
     ]
    }
   ],
   "source": [
    "#task01\n",
    "import psycopg2\n",
    "\n",
    "# all tables\n",
    "tables = ['category', 'film_category', 'film', 'language', 'film_actor', 'inventory', \n",
    "          'rental', 'payment', 'staff', 'actor', 'customer', 'address', 'city', 'country', 'store']\n",
    "\n",
    "results = {\n",
    "    'category':0, 'film_category':0, 'film':0, 'language':0, 'film_actor':0, 'inventory':0, \n",
    "          'rental':0, 'payment':0, 'staff':0, 'actor':0, 'customer':0, 'address':0, 'city':0, 'country':0, 'store':0\n",
    "}\n",
    "\n",
    "db_conn = psycopg2.connect(host='10.34.124.114', dbname='dvdrental', user='dxlab', password='wistron888')\n",
    "print('Connect [postgres] database successfully!')\n",
    "\n",
    "# write your code below\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cur = db_conn.cursor()\n",
    "\n",
    "for table in tables:\n",
    "    # 執行你的SQL\n",
    "    cur.execute(f\"SELECT COUNT(1) FROM {table}\")\n",
    "    results[table] = cur.fetchone()\n",
    "    \n",
    "db_conn.close()\n",
    "# print out the final result\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d665410",
   "metadata": {},
   "source": [
    "## 作業#04\n",
    "\n",
    "請使用DBAPI來連結到這個範例資料庫, 並且執行一個Left-join結果的Query然後把結果存成一個CSV檔(`join_query.csv`)。\n",
    "CSV的檔案必需要包含欄位名稱(column in 1st row), 欄位之間以\",\"來分隔。並且把這個檔案上傳到學員個人的bucket(`de+{工號}`)。\n",
    "\n",
    "**S3 連接參數**\n",
    "\n",
    "請使用以下的帳號來登入Minio, 每個學員都是不同的登入帳號與密碼:\n",
    "\n",
    "* `endpoint_url` (s3服務的網路位址): **http://10.34.124.114:9000**\n",
    "* `aws_access_key_id` (使用者帳號): **demo**\n",
    "* `aws_secret_access_key` (使用者密碼): **demo8888**\n",
    "* `region_name` (區域編碼): **us-east-1**\n",
    "\n",
    "* `object_key`: **join_query.csv**\n",
    "\n",
    "\n",
    "**CSV導出參考**: https://gist.github.com/madan712/f27ac3b703a541abbcd63871a4a56636\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    film.film_id,\n",
    "    title,\n",
    "    inventory_id\n",
    "FROM\n",
    "    film\n",
    "LEFT JOIN inventory \n",
    "    ON inventory.film_id = film.film_id\n",
    "ORDER BY title;\n",
    "```\n",
    "\n",
    "\n",
    "![](images/film-and-inventory-tables.png)\n",
    "\n",
    "**SQL語法參考**: https://www.postgresqltutorial.com/postgresql-left-join/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a0af18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect [postgres] database successfully!\n",
      "Upload file to MinIO successfully\n"
     ]
    }
   ],
   "source": [
    "#task02\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "stmt = \"\"\"\n",
    "SELECT\n",
    "    film.film_id,\n",
    "    title,\n",
    "    inventory_id\n",
    "FROM\n",
    "    film\n",
    "LEFT JOIN inventory \n",
    "    ON inventory.film_id = film.film_id\n",
    "ORDER BY title;\n",
    "\"\"\"\n",
    "MY_BUCKET_NAME = 'dez18033044'\n",
    "MY_OBJECT_KEY = 'join_query.csv'\n",
    "\n",
    "db_conn = psycopg2.connect(host='10.34.124.114', dbname='dvdrental', user='dxlab', password='wistron888')\n",
    "print('Connect [postgres] database successfully!')\n",
    "\n",
    "# write your code below\n",
    "cursor = db_conn.cursor()\n",
    "\n",
    "cursor.execute(stmt)\n",
    "# Get the query title name and content\n",
    "query_title = [desc[0] for desc in cursor.description]\n",
    "\n",
    "query_list = []\n",
    "for each in cursor.fetchall():\n",
    "    query_list.append(list(each))\n",
    "\n",
    "# Convert query result as a DataFrame\n",
    "df_inventory = pd.DataFrame(query_list, columns=query_title)\n",
    "\n",
    "df_inventory.to_csv('join_query.csv', sep=',', index=False)\n",
    "# Upload csv to MinIO\n",
    "s3_resource = boto3.resource('s3',\n",
    "                    endpoint_url='http://10.34.124.114:9500',\n",
    "                    aws_access_key_id='demo',\n",
    "                    aws_secret_access_key='demo8888',\n",
    "                    region_name='us-east-1')\n",
    "s3_resource.Bucket(MY_BUCKET_NAME).upload_file(Key=MY_OBJECT_KEY, Filename=\"join_query.csv\")\n",
    "print('Upload file to MinIO successfully')\n",
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c42be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
